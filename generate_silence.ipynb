{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "SAMPLE_LENGTH = 16000\n",
    "RMS_TARGET = 0.02\n",
    "MAX_NOISES = 3\n",
    "\n",
    "SPLITS = {\n",
    "    \"train\": 2000,\n",
    "    \"val\": 250,\n",
    "    \"test\": 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Don't change the SEED value\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the data directory containing the rest of the dataset\n",
    "data_dir =  \"/home/robin/Bureau/ETUDES/M2/S2/TAP/Projet-Traitement-Automatique-de-la-Parole/Dataset/speech_commands_v0.02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(path):\n",
    "    sr, audio = wavfile.read(path)\n",
    "    return audio.astype(np.float32) / 32768.0, sr\n",
    "\n",
    "def load_noises(noise_dir):\n",
    "    noises = []\n",
    "    for fname in os.listdir(noise_dir):\n",
    "        if fname.endswith(\".wav\"):\n",
    "            audio, sr = load_wav(os.path.join(noise_dir, fname))\n",
    "            assert sr == SAMPLE_RATE\n",
    "            noises.append(audio.astype(np.float32))\n",
    "    return noises\n",
    "\n",
    "\n",
    "def random_crop(signal, length):\n",
    "    if len(signal) < length:\n",
    "        return np.pad(signal, (0, length - len(signal)))\n",
    "    start = np.random.randint(0, len(signal) - length)\n",
    "    return signal[start:start + length]\n",
    "\n",
    "\n",
    "def generate_silence(noises):\n",
    "    n_mix = random.randint(1, MAX_NOISES)\n",
    "    selected = random.sample(noises, n_mix)\n",
    "\n",
    "    mix = np.zeros(SAMPLE_LENGTH, dtype=np.float32)\n",
    "\n",
    "    for noise in selected:\n",
    "        crop = random_crop(noise, SAMPLE_LENGTH)\n",
    "        weight = np.random.uniform(0.3, 1.0)\n",
    "        mix += weight * crop\n",
    "\n",
    "    rms = np.sqrt(np.mean(mix ** 2))\n",
    "    if rms > 0:\n",
    "        mix *= RMS_TARGET / rms\n",
    "\n",
    "    return mix\n",
    "\n",
    "\n",
    "def save_wav(path, audio):\n",
    "    audio = np.clip(audio, -1.0, 1.0)\n",
    "    wavfile.write(\n",
    "        path,\n",
    "        16000,\n",
    "        (audio * 32767).astype(np.int16)\n",
    "    )\n",
    "\n",
    "def write_split_to_file(out_dir, split, files_names):\n",
    "    with open(os.path.join(out_dir, f\"{split}_silence_list.txt\"), \"w\") as f:\n",
    "        for fname in files_names:\n",
    "            f.write(fname + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split(noises, out_dir, n_samples, split_name):\n",
    "    files_names = []\n",
    "    for i in range(n_samples):\n",
    "        silence = generate_silence(noises)\n",
    "        fname = f\"{split_name}_{i:05d}.wav\"\n",
    "        save_wav(os.path.join(out_dir, fname), silence)\n",
    "        files_names.append(f\"silence/{fname}\")\n",
    "    return files_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7337/2617875801.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sr, audio = wavfile.read(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le split train on a 2000 fichiers.\n",
      "Pour le split val on a 250 fichiers.\n",
      "Pour le split test on a 250 fichiers.\n"
     ]
    }
   ],
   "source": [
    "noise_dir = os.path.join(data_dir, \"_background_noise_\")\n",
    "output_root = os.path.join(data_dir, \"silence\")\n",
    "\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "noises = load_noises(noise_dir)\n",
    "\n",
    "for split, n_samples in SPLITS.items():\n",
    "    files_names = generate_split(\n",
    "        noises,\n",
    "        output_root,\n",
    "        n_samples,\n",
    "        split\n",
    "    )\n",
    "    assert len(files_names) == n_samples\n",
    "    print(f\"Pour le split {split} on a {len(files_names)} fichiers.\")\n",
    "    write_split_to_file(data_dir, split, files_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tap_tp_partie1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
